commands.txt  databricks-dolly-15k.jsonl  generation_config.json  logs.txt                          model-00002-of-00002.safetensors  special_tokens_map.json  test_l3.py     tokenizer
config.json   generate_logs.txt           hh.py                   model-00001-of-00002.safetensors  model.safetensors.index.json      student_model.pt         test_llama.py


Inside tokenizer:
tokenizer_config.json  tokenizer.json

commands.txt:

Training Mode
python train_student_model.py --mode train --data h.jsonl --config_path config.json --teacher llama3.2
Evaluation Mode
python train_student_model.py --mode evaluate --model_path student_model.pt --test_data h.jsonl --config_path config.json --teacher llama3.2
Text Generation Mode
python train_student_model.py --mode generate --model_path student_model.pt --prompt "What is the difference between " --gen_max_len 100 --config_path config.json --teacher llama3.2

train_student_model.py -->hh.py
